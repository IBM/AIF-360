{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Trusted-AI/AIF360/blob/master/examples/demo_calibrated_eqodds_postprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aif360[LawSchoolGPA,Reductions] in /Users/zeen/anaconda3/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (1.10.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (3.7.1)\n",
      "Requirement already satisfied: tempeh in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (0.1.12)\n",
      "Requirement already satisfied: fairlearn~=0.7 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from aif360[LawSchoolGPA,Reductions]) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.0->aif360[LawSchoolGPA,Reductions]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.0->aif360[LawSchoolGPA,Reductions]) (2022.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->aif360[LawSchoolGPA,Reductions]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->aif360[LawSchoolGPA,Reductions]) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from matplotlib->aif360[LawSchoolGPA,Reductions]) (3.0.9)\n",
      "Requirement already satisfied: memory-profiler in /Users/zeen/anaconda3/lib/python3.11/site-packages (from tempeh->aif360[LawSchoolGPA,Reductions]) (0.61.0)\n",
      "Requirement already satisfied: pytest in /Users/zeen/anaconda3/lib/python3.11/site-packages (from tempeh->aif360[LawSchoolGPA,Reductions]) (7.4.0)\n",
      "Requirement already satisfied: requests in /Users/zeen/anaconda3/lib/python3.11/site-packages (from tempeh->aif360[LawSchoolGPA,Reductions]) (2.31.0)\n",
      "Requirement already satisfied: shap in /Users/zeen/anaconda3/lib/python3.11/site-packages (from tempeh->aif360[LawSchoolGPA,Reductions]) (0.42.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->aif360[LawSchoolGPA,Reductions]) (1.16.0)\n",
      "Requirement already satisfied: psutil in /Users/zeen/anaconda3/lib/python3.11/site-packages (from memory-profiler->tempeh->aif360[LawSchoolGPA,Reductions]) (5.9.0)\n",
      "Requirement already satisfied: iniconfig in /Users/zeen/anaconda3/lib/python3.11/site-packages (from pytest->tempeh->aif360[LawSchoolGPA,Reductions]) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from pytest->tempeh->aif360[LawSchoolGPA,Reductions]) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from requests->tempeh->aif360[LawSchoolGPA,Reductions]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from requests->tempeh->aif360[LawSchoolGPA,Reductions]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from requests->tempeh->aif360[LawSchoolGPA,Reductions]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from requests->tempeh->aif360[LawSchoolGPA,Reductions]) (2023.7.22)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from shap->tempeh->aif360[LawSchoolGPA,Reductions]) (4.65.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from shap->tempeh->aif360[LawSchoolGPA,Reductions]) (0.0.7)\n",
      "Requirement already satisfied: numba in /Users/zeen/anaconda3/lib/python3.11/site-packages (from shap->tempeh->aif360[LawSchoolGPA,Reductions]) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/zeen/anaconda3/lib/python3.11/site-packages (from shap->tempeh->aif360[LawSchoolGPA,Reductions]) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/zeen/anaconda3/lib/python3.11/site-packages (from numba->shap->tempeh->aif360[LawSchoolGPA,Reductions]) (0.40.0)\n"
     ]
    }
   ],
   "source": [
    "# Install AIF360\n",
    "!pip install 'aif360[LawSchoolGPA,Reductions]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult dataset is available for us\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import aif360\n",
    "\n",
    "# Obtain the location where it is installed\n",
    "LIB_PATH = aif360.__file__.rsplit(\"aif360\", 1)[0]\n",
    "\n",
    "# check if the data got download properly\n",
    "def check_data_or_download(destn, files, data_source_directory):\n",
    "    check = all(item in os.listdir(destn) for item in files)\n",
    "    if check:\n",
    "        print(\"Adult dataset is available for us\")\n",
    "    else:\n",
    "        print(\"Some files are missing. Downloading now.\")\n",
    "        for data_file in files:\n",
    "            _ = urllib.request.urlretrieve(data_source_directory + data_file,\n",
    "                                           os.path.join(destn, data_file))\n",
    "    \n",
    "# Download adult dataset\n",
    "data_source_directory = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/\"\n",
    "destn = os.path.join(LIB_PATH, \"aif360\", \"data\", \"raw\", \"adult\")\n",
    "files = [\"adult.data\", \"adult.test\", \"adult.names\"]\n",
    "\n",
    "check_data_or_download(destn, files, data_source_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of an odds-equalizing post-processing algorithm for bias mitigiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "                import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
     ]
    }
   ],
   "source": [
    "## import dataset\n",
    "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "    dataset_orig = AdultDataset()\n",
    "#     dataset_orig = load_preproc_data_adult()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "    dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    dataset_orig = load_preproc_data_compas()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]    \n",
    "\n",
    "# cost constraint of fnr will optimize generalized false negative rates, that of\n",
    "# fpr will optimize generalized false positive rates, and weighted will optimize\n",
    "# a weighted combination of both\n",
    "cost_constraint = \"fnr\" # \"fnr\", \"fpr\", \"weighted\"\n",
    "#random seed for calibrated equal odds prediction\n",
    "randseed = 12345679 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset into train, validation, and test partitions (70-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.6], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27133, 98)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'education-num', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'workclass=Federal-gov', 'workclass=Local-gov', 'workclass=Private', 'workclass=Self-emp-inc', 'workclass=Self-emp-not-inc', 'workclass=State-gov', 'workclass=Without-pay', 'education=10th', 'education=11th', 'education=12th', 'education=1st-4th', 'education=5th-6th', 'education=7th-8th', 'education=9th', 'education=Assoc-acdm', 'education=Assoc-voc', 'education=Bachelors', 'education=Doctorate', 'education=HS-grad', 'education=Masters', 'education=Preschool', 'education=Prof-school', 'education=Some-college', 'marital-status=Divorced', 'marital-status=Married-AF-spouse', 'marital-status=Married-civ-spouse', 'marital-status=Married-spouse-absent', 'marital-status=Never-married', 'marital-status=Separated', 'marital-status=Widowed', 'occupation=Adm-clerical', 'occupation=Armed-Forces', 'occupation=Craft-repair', 'occupation=Exec-managerial', 'occupation=Farming-fishing', 'occupation=Handlers-cleaners', 'occupation=Machine-op-inspct', 'occupation=Other-service', 'occupation=Priv-house-serv', 'occupation=Prof-specialty', 'occupation=Protective-serv', 'occupation=Sales', 'occupation=Tech-support', 'occupation=Transport-moving', 'relationship=Husband', 'relationship=Not-in-family', 'relationship=Other-relative', 'relationship=Own-child', 'relationship=Unmarried', 'relationship=Wife', 'native-country=Cambodia', 'native-country=Canada', 'native-country=China', 'native-country=Columbia', 'native-country=Cuba', 'native-country=Dominican-Republic', 'native-country=Ecuador', 'native-country=El-Salvador', 'native-country=England', 'native-country=France', 'native-country=Germany', 'native-country=Greece', 'native-country=Guatemala', 'native-country=Haiti', 'native-country=Holand-Netherlands', 'native-country=Honduras', 'native-country=Hong', 'native-country=Hungary', 'native-country=India', 'native-country=Iran', 'native-country=Ireland', 'native-country=Italy', 'native-country=Jamaica', 'native-country=Japan', 'native-country=Laos', 'native-country=Mexico', 'native-country=Nicaragua', 'native-country=Outlying-US(Guam-USVI-etc)', 'native-country=Peru', 'native-country=Philippines', 'native-country=Poland', 'native-country=Portugal', 'native-country=Puerto-Rico', 'native-country=Scotland', 'native-country=South', 'native-country=Taiwan', 'native-country=Thailand', 'native-country=Trinadad&Tobago', 'native-country=United-States', 'native-country=Vietnam', 'native-country=Yugoslavia']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for the original datasets (without any classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.204023\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original validation dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.200160\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.182252\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "metric_orig_valid = BinaryLabelDatasetMetric(dataset_orig_valid, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original validation dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_valid.mean_difference())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier (logistic regression on original training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Placeholder for predicted and transformed datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for validation and testing data\n",
    "X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
    "y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
    "\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "    \n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results before post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.1231072453144734\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.09162399950032801\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted validation dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.12083796425190826\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.04493160251673933\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted testing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.12062535171739189\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.10919441704983168\n"
     ]
    }
   ],
   "source": [
    "cm_pred_train = ClassificationMetric(dataset_orig_train, dataset_orig_train_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted training dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_valid = ClassificationMetric(dataset_orig_valid, dataset_orig_valid_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted validation dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_test = ClassificationMetric(dataset_orig_test, dataset_orig_test_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted testing dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_negative_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform odds equalizing post processing on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds equalizing post-processing algorithm\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups = privileged_groups,\n",
    "                                     unprivileged_groups = unprivileged_groups,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)\n",
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform validation and test data using the post processing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_valid_pred = cpp.predict(dataset_orig_valid_pred)\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results after post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original-Transformed validation dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.14134042716418774\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.0030010098085488934\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original-Transformed testing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.14080189356327238\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.06497225668114187\n"
     ]
    }
   ],
   "source": [
    "cm_transf_valid = ClassificationMetric(dataset_orig_valid, dataset_transf_valid_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Transformed validation dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_valid.difference(cm_transf_valid.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate))\n",
    "\n",
    "cm_transf_test = ClassificationMetric(dataset_orig_test, dataset_transf_test_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Transformed testing dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test.difference(cm_transf_test.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test.difference(cm_transf_test.generalized_false_negative_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing: Check if the rates for validation data has gone down\n",
    "assert np.abs(cm_transf_valid.difference(cm_transf_valid.generalized_false_negative_rate)) < np.abs(cm_pred_valid.difference(cm_pred_valid.generalized_false_negative_rate)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Classification thresholds used for validation and parameter selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████▎                    | 13/25 [00:02<00:01,  6.85it/s]"
     ]
    }
   ],
   "source": [
    "# Thresholds\n",
    "all_thresh = np.linspace(0.01, 0.99, 25)\n",
    "display(Markdown(\"#### Classification thresholds used for validation and parameter selection\"))\n",
    "\n",
    "bef_avg_odds_diff_test = []\n",
    "bef_avg_odds_diff_valid = []\n",
    "aft_avg_odds_diff_test = []\n",
    "aft_avg_odds_diff_valid = []\n",
    "bef_bal_acc_valid = []\n",
    "bef_bal_acc_test = []\n",
    "aft_bal_acc_valid = []\n",
    "aft_bal_acc_test = []\n",
    "for thresh in tqdm(all_thresh):\n",
    "    \n",
    "    dataset_orig_valid_pred_thresh = dataset_orig_valid_pred.copy(deepcopy=True)\n",
    "    dataset_orig_test_pred_thresh = dataset_orig_test_pred.copy(deepcopy=True)\n",
    "    dataset_transf_valid_pred_thresh = dataset_transf_valid_pred.copy(deepcopy=True)\n",
    "    dataset_transf_test_pred_thresh = dataset_transf_test_pred.copy(deepcopy=True)\n",
    "    \n",
    "    # Labels for the datasets from scores\n",
    "    y_temp = np.zeros_like(dataset_orig_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_valid_pred_thresh.scores >= thresh] = dataset_orig_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_valid_pred_thresh.scores >= thresh)] = dataset_orig_valid_pred_thresh.unfavorable_label\n",
    "    dataset_orig_valid_pred_thresh.labels = y_temp\n",
    "\n",
    "    y_temp = np.zeros_like(dataset_orig_test_pred_thresh.labels)\n",
    "    y_temp[dataset_orig_test_pred_thresh.scores >= thresh] = dataset_orig_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_orig_test_pred_thresh.scores >= thresh)] = dataset_orig_test_pred_thresh.unfavorable_label\n",
    "    dataset_orig_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_valid_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_valid_pred_thresh.scores >= thresh] = dataset_transf_valid_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_valid_pred_thresh.scores >= thresh)] = dataset_transf_valid_pred_thresh.unfavorable_label\n",
    "    dataset_transf_valid_pred_thresh.labels = y_temp\n",
    "    \n",
    "    y_temp = np.zeros_like(dataset_transf_test_pred_thresh.labels)\n",
    "    y_temp[dataset_transf_test_pred_thresh.scores >= thresh] = dataset_transf_test_pred_thresh.favorable_label\n",
    "    y_temp[~(dataset_transf_test_pred_thresh.scores >= thresh)] = dataset_transf_test_pred_thresh.unfavorable_label\n",
    "    dataset_transf_test_pred_thresh.labels = y_temp\n",
    "    \n",
    "    # Metrics for original validation data\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                                 dataset_orig_valid_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_valid.append(classified_metric_orig_valid.equal_opportunity_difference())\n",
    "\n",
    "    bef_bal_acc_valid.append(0.5*(classified_metric_orig_valid.true_positive_rate()+\n",
    "                              classified_metric_orig_valid.true_negative_rate()))\n",
    "\n",
    "    classified_metric_orig_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_orig_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    bef_avg_odds_diff_test.append(classified_metric_orig_test.equal_opportunity_difference())\n",
    "    bef_bal_acc_test.append(0.5*(classified_metric_orig_test.true_positive_rate()+\n",
    "                              classified_metric_orig_test.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validing data\n",
    "    classified_metric_transf_valid = ClassificationMetric(\n",
    "                                     dataset_orig_valid, \n",
    "                                     dataset_transf_valid_pred_thresh,\n",
    "                                     unprivileged_groups=unprivileged_groups,\n",
    "                                     privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_valid.append(classified_metric_transf_valid.equal_opportunity_difference())\n",
    "    aft_bal_acc_valid.append(0.5*(classified_metric_transf_valid.true_positive_rate()+\n",
    "                              classified_metric_transf_valid.true_negative_rate()))\n",
    "\n",
    "    # Metrics for transf validation data\n",
    "    classified_metric_transf_test = ClassificationMetric(dataset_orig_test,\n",
    "                                                 dataset_transf_test_pred_thresh,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    aft_avg_odds_diff_test.append(classified_metric_transf_test.equal_opportunity_difference())\n",
    "    aft_bal_acc_test.append(0.5*(classified_metric_transf_test.true_positive_rate()+\n",
    "                                  classified_metric_transf_test.true_negative_rate()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_valid = np.array(bef_bal_acc_valid)\n",
    "bef_avg_odds_diff_valid = np.array(bef_avg_odds_diff_valid)\n",
    "\n",
    "aft_bal_acc_valid = np.array(aft_bal_acc_valid)\n",
    "aft_avg_odds_diff_valid = np.array(aft_avg_odds_diff_valid)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_valid, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_valid, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed validation data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_valid), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_valid), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "             \"Equal opp. diff. - Orig.\",\"Equal opp. diff. - Postproc.\",], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bef_bal_acc_test = np.array(bef_bal_acc_test)\n",
    "bef_avg_odds_diff_test = np.array(bef_avg_odds_diff_test)\n",
    "\n",
    "aft_bal_acc_test = np.array(aft_bal_acc_test)\n",
    "aft_avg_odds_diff_test = np.array(aft_avg_odds_diff_test)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13,7))\n",
    "ax1.plot(all_thresh, bef_bal_acc_test, color='b')\n",
    "ax1.plot(all_thresh, aft_bal_acc_test, color='b', linestyle='dashed')\n",
    "ax1.set_title('Original and Postprocessed testing data', fontsize=16, fontweight='bold')\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(all_thresh, np.abs(bef_avg_odds_diff_test), color='r')\n",
    "ax2.plot(all_thresh, np.abs(aft_avg_odds_diff_test), color='r', linestyle='dashed')\n",
    "ax2.set_ylabel('abs(Equal opportunity diff)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "fig.legend([\"Balanced Acc. - Orig.\", \"Balanced Acc. - Postproc.\",\n",
    "            \"Equal opp. diff. - Orig.\", \"Equal opp. diff. - Postproc.\"], \n",
    "           fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
