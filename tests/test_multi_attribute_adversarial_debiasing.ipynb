{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook demonstrates the use of adversarial debiasing algorithm to learn a fair classifier.\n",
    "Adversarial debiasing [1] is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary's ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit. We will see how to use this algorithm for learning models with and without fairness constraints and apply them on the Adult dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.inprocessing.multi_attribute_adversarial_debiasing import *\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predicted_labels, true), dtype=tf.float32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_compas()#load_preproc_data_adult()#\n",
    "\n",
    "privileged_groups = [{'sex': 1}, {'race': 1}]\n",
    "unprivileged_groups = [{'sex': 0}, {'race': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3694, 10)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race', 'age_cat=25 to 45', 'age_cat=Greater than 45', 'age_cat=Less than 25', 'priors_count=0', 'priors_count=1 to 3', 'priors_count=More than 3', 'c_charge_degree=F', 'c_charge_degree=M']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate metric for original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.134150\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.136590\n",
      "\n",
      "\n",
      "race\n",
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.158091\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.072146\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for unprivileged_group, privileged_group in zip (unprivileged_groups, privileged_groups):\n",
    "    print('Sensitive attribute : ', list(unprivileged_group.keys())[0], '\\n')\n",
    "\n",
    "\n",
    "    # Metric for the original dataset\n",
    "    metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                                unprivileged_groups=[unprivileged_group],\n",
    "                                                privileged_groups=[privileged_group])\n",
    "    \n",
    "    print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "    metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                                unprivileged_groups=[unprivileged_group],\n",
    "                                                privileged_groups=[privileged_group])\n",
    "    print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())\n",
    "    print('\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()#MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debias multiple sensitive attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'race']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example dataset\n",
    "features = dataset_orig_train.features\n",
    "labels = dataset_orig_train.labels\n",
    "protected_attributes = dataset_orig_train.protected_attributes\n",
    "\n",
    "dataset_orig_train.protected_attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "nb_pretrain = 10\n",
    "batch_size = 64\n",
    "total_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Classifier - Epoch 1, Loss: 0.6997118592262268\n",
      "Pretraining Classifier - Epoch 2, Loss: 0.7821968793869019\n",
      "Pretraining Classifier - Epoch 3, Loss: 0.5729279518127441\n",
      "Pretraining Classifier - Epoch 4, Loss: 0.6386002898216248\n",
      "Pretraining Classifier - Epoch 5, Loss: 0.46196913719177246\n",
      "Pretraining Classifier - Epoch 6, Loss: 0.6169740557670593\n",
      "Pretraining Classifier - Epoch 7, Loss: 0.5328130722045898\n",
      "Pretraining Classifier - Epoch 8, Loss: 0.5376180410385132\n",
      "Pretraining Classifier - Epoch 9, Loss: 0.5474033951759338\n",
      "Pretraining Classifier - Epoch 10, Loss: 0.6379567980766296\n"
     ]
    }
   ],
   "source": [
    "# Create a trainer\n",
    "trainer = AdversarialDebiasor(loss_weights = [2, 5])#[2, 4])##.5,.5\n",
    "\n",
    "# Pretrain the classifier model\n",
    "trainer.pretrain_classifier(features, labels, num_epochs=nb_pretrain, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive attribute :  sex\n",
      "\tEqual opportunity diff. : -0.1346140883046849\n",
      "\tAv. Odds diff.          : -0.14690302396562968 \n",
      "\n",
      "\n",
      "Sensitive attribute :  race\n",
      "\tEqual opportunity diff. : -0.10410880506320597\n",
      "\tAv. Odds diff.          : -0.1449018645342491 \n",
      "\n",
      "\n",
      "\n",
      "Accuracy        :  0.6439394\n",
      "Balanced accuracy :  0.6373624259216502\n",
      "AUC score         :  0.6721495869570795\n"
     ]
    }
   ],
   "source": [
    "# Evaluate metrics\n",
    "\n",
    "metrics = trainer.get_classification_metrics(dataset_orig_test)\n",
    "\n",
    "for key, classified_metric_debiasing_test in metrics.items():\n",
    "    print('Sensitive attribute : ', key)\n",
    "\n",
    "    eod = classified_metric_debiasing_test.equal_opportunity_difference()\n",
    "    aod = classified_metric_debiasing_test.average_odds_difference()\n",
    "    ti = classified_metric_debiasing_test.theil_index()\n",
    "    print('\\tEqual opportunity diff. :', eod)\n",
    "    print('\\tAv. Odds diff.          :', aod, '\\n'*2)\n",
    "\n",
    "\n",
    "predicted_labels = trainer.predict(dataset_orig_test.features)\n",
    "true_labels = dataset_orig_test.labels\n",
    "\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "\n",
    "# Should not change since only trained adversary\n",
    "print('\\nAccuracy        : ', accuracy(predicted_labels, true_labels).numpy())\n",
    "print('Balanced accuracy : ', bal_acc_debiasing_test)\n",
    "print('AUC score         : ', roc_auc_score(true_labels, trainer.predict_proba(dataset_orig_test.features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Adversary - Epoch 1, Loss: 4.554468631744385\n",
      "Pretraining Adversary - Epoch 2, Loss: 4.257065296173096\n",
      "Pretraining Adversary - Epoch 3, Loss: 3.8502635955810547\n",
      "Pretraining Adversary - Epoch 4, Loss: 4.026779651641846\n",
      "Pretraining Adversary - Epoch 5, Loss: 4.1616621017456055\n",
      "Pretraining Adversary - Epoch 6, Loss: 3.41196870803833\n",
      "Pretraining Adversary - Epoch 7, Loss: 3.6854116916656494\n",
      "Pretraining Adversary - Epoch 8, Loss: 3.7127201557159424\n",
      "Pretraining Adversary - Epoch 9, Loss: 3.7646265029907227\n",
      "Pretraining Adversary - Epoch 10, Loss: 3.9085896015167236\n",
      "Epoch 1, Classifier Loss: 0.8034292459487915, Adversary Loss: 5.14768648147583\n",
      "Epoch 2, Classifier Loss: 0.7351345419883728, Adversary Loss: 4.93751859664917\n",
      "Epoch 3, Classifier Loss: 0.5497244596481323, Adversary Loss: 4.192628383636475\n",
      "Epoch 4, Classifier Loss: 0.6802529096603394, Adversary Loss: 4.399204730987549\n",
      "Epoch 5, Classifier Loss: 0.6360391974449158, Adversary Loss: 4.44249153137207\n",
      "Epoch 6, Classifier Loss: 0.6069614291191101, Adversary Loss: 4.247575759887695\n",
      "Epoch 7, Classifier Loss: 0.6291248798370361, Adversary Loss: 4.482082366943359\n",
      "Epoch 8, Classifier Loss: 0.6391543745994568, Adversary Loss: 4.2197723388671875\n",
      "Epoch 9, Classifier Loss: 0.6081776022911072, Adversary Loss: 4.617678642272949\n",
      "Epoch 10, Classifier Loss: 0.6225768327713013, Adversary Loss: 4.75014591217041\n",
      "Epoch 11, Classifier Loss: 0.6743019223213196, Adversary Loss: 3.333232879638672\n",
      "Epoch 12, Classifier Loss: 0.6646288633346558, Adversary Loss: 4.252073287963867\n",
      "Epoch 13, Classifier Loss: 0.5460391044616699, Adversary Loss: 4.165338039398193\n",
      "Epoch 14, Classifier Loss: 0.6624656319618225, Adversary Loss: 4.3580780029296875\n",
      "Epoch 15, Classifier Loss: 0.6271290183067322, Adversary Loss: 3.967176675796509\n",
      "Epoch 16, Classifier Loss: 0.6059078574180603, Adversary Loss: 4.372767925262451\n",
      "Epoch 17, Classifier Loss: 0.6996213793754578, Adversary Loss: 4.258504867553711\n",
      "Epoch 18, Classifier Loss: 0.5941512584686279, Adversary Loss: 4.239222526550293\n",
      "Epoch 19, Classifier Loss: 0.6514211893081665, Adversary Loss: 4.041526794433594\n",
      "Epoch 20, Classifier Loss: 0.6756848692893982, Adversary Loss: 4.375195503234863\n",
      "Epoch 21, Classifier Loss: 0.5535308718681335, Adversary Loss: 4.016950607299805\n",
      "Epoch 22, Classifier Loss: 0.6133072376251221, Adversary Loss: 4.103389739990234\n",
      "Epoch 23, Classifier Loss: 0.654258131980896, Adversary Loss: 4.51798152923584\n",
      "Epoch 24, Classifier Loss: 0.4701286852359772, Adversary Loss: 5.2090864181518555\n",
      "Epoch 25, Classifier Loss: 0.6915785670280457, Adversary Loss: 3.9661507606506348\n",
      "Epoch 26, Classifier Loss: 0.5089432001113892, Adversary Loss: 4.515471458435059\n",
      "Epoch 27, Classifier Loss: 0.5863111019134521, Adversary Loss: 4.468857765197754\n",
      "Epoch 28, Classifier Loss: 0.6279569268226624, Adversary Loss: 4.021674156188965\n",
      "Epoch 29, Classifier Loss: 0.6106312274932861, Adversary Loss: 4.34522008895874\n",
      "Epoch 30, Classifier Loss: 0.5724514722824097, Adversary Loss: 4.230558395385742\n"
     ]
    }
   ],
   "source": [
    "# pretrain the adversary on trained classifier's outputs\n",
    "trainer.pretrain_adversary(features, labels, protected_attributes, num_epochs=nb_pretrain, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both models together\n",
    "trainer.train(features, labels, protected_attributes, num_epochs=total_epochs, batch_size=batch_size)\n",
    "\n",
    "predicted_labels = trainer.predict(dataset_orig_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive attribute :  sex \n",
      "\n",
      "\tEqual opportunity diff. : -0.0002471632400853352\n",
      "\tAv. Odds diff.          : 0.008075483386319304 \n",
      "\n",
      "\n",
      "Sensitive attribute :  race \n",
      "\n",
      "\tEqual opportunity diff. : 0.04186234408927947\n",
      "\tAv. Odds diff.          : 0.006450227193240843 \n",
      "\n",
      "\n",
      "Accuracy          :  0.62752527\n",
      "Balanced accuracy :  0.6203725082736858\n",
      "AUC score         :  0.6634093037276483\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.get_classification_metrics(dataset_orig_test)\n",
    "\n",
    "for key, classified_metric_debiasing_test in metrics.items():\n",
    "    print('Sensitive attribute : ', key, '\\n')\n",
    "\n",
    "    TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "    TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "    bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "    eod = classified_metric_debiasing_test.equal_opportunity_difference()\n",
    "    aod = classified_metric_debiasing_test.average_odds_difference()\n",
    "    ti = classified_metric_debiasing_test.theil_index()\n",
    "    print('\\tEqual opportunity diff. :', eod)\n",
    "    print('\\tAv. Odds diff.          :', aod, '\\n'*2)\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy          : ', accuracy(predicted_labels, true_labels).numpy())\n",
    "print('Balanced accuracy : ', bal_acc_debiasing_test)\n",
    "print('AUC score         : ', roc_auc_score(true_labels, trainer.predict_proba(dataset_orig_test.features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive attribute :  sex\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.026899\n",
      "\n",
      "\n",
      "Sensitive attribute :  race\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.007242\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dmetrics = trainer.get_dataset_metrics(dataset_orig_test)\n",
    "\n",
    "for key, classified_metric_debiasing_test in metrics.items():\n",
    "    print('Sensitive attribute : ', key)\n",
    "    print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % classified_metric_debiasing_test.mean_difference())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    References:\n",
    "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
    "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
